{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on a besoin de path_to_code pour pouvoir importer paths.py, le serpent se mort la queue :D\n",
    "path_to_code = 'C:/Nicolas/M2 MVA/ALTEGRAD/Kaggle/text_and_graph/code'\n",
    "# path_to_code = \"/Users/estelleaflalo/Desktop/M2_Data_Science/Second_Period/Text_and_Graph/Project/text_and_graph/code/\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(path_to_code)\n",
    "\n",
    "from paths import path\n",
    "\n",
    "path_to_code, path_to_data, path_to_results = path(\"nicolas\")\n",
    "\n",
    "import numpy as np\n",
    "from init import split, init_dic, csv_to_sub\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from numpy.linalg import norm\n",
    "from loss_function import score\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dictionnaries\n0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "\n",
    "training_info = pd.read_csv(path_to_data + 'training_info.csv', sep=',', header=0)\n",
    "\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "\n",
    "test_info = pd.read_csv(path_to_data + 'test_info.csv', sep=',', header=0)\n",
    "\n",
    "print \"Building dictionnaries\"\n",
    "\n",
    "_, all_senders, _, address_books, _ = init_dic(training, training_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_recs_per_sender(train_info_S):\n",
    "    \"\"\"\n",
    "    For a fixed sender, return the list of all the recipients of this sender in the training set.\n",
    "    :param train_info_S: A structure like train_info, but for one sender only, since we work sender by sender\n",
    "    :return: a list of all the recipients for the current sender\n",
    "    \"\"\"\n",
    "    all_recs = []\n",
    "    for recs in train_info_S['recipients'].values:\n",
    "        all_recs.extend(recs.split(' '))\n",
    "\n",
    "    all_recs = list(set(all_recs))\n",
    "    return all_recs\n",
    "\n",
    "\n",
    "X_train, Y_train, X_test = csv_to_sub(training, training_info, test, test_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter use_idf is set to True\nparameter K is set to 20\nTo build the vocabulary, the tfidfVectorizer will use max_df=0.95 and min_df=1\nThe tf is replaced by (1 + log(tf))\n"
     ]
    }
   ],
   "source": [
    "use_idf = True\n",
    "print 'Parameter use_idf is set to {}'.format(use_idf)\n",
    "\n",
    "\n",
    "K=20\n",
    "\n",
    "\n",
    "print 'parameter K is set to {}'.format(K)\n",
    "max_df = 0.95\n",
    "min_df = 1\n",
    "print 'To build the vocabulary, the tfidfVectorizer will use max_df={} and min_df={}'.format(max_df, min_df)\n",
    "sublinear_tf  = True # default is False in sklearn\n",
    "if sublinear_tf:\n",
    "    print 'The tf is replaced by (1 + log(tf))'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=1\n",
    "sender = all_senders[index]\n",
    "X_train_S = X_train[sender]\n",
    "X_dev_S = X_test[sender]\n",
    "Y_train_S = Y_train[sender]\n",
    "\n",
    "##############Create TF IDF vector from mails sent by sender S\n",
    "\n",
    "\n",
    "# vectorize mails sent by a unique sender\n",
    "vectorizer_sender = TfidfVectorizer(max_df=0.95, stop_words='english', use_idf=use_idf, sublinear_tf=sublinear_tf)\n",
    "\n",
    "# train\n",
    "training_info_S = training_info.loc[training_info['mid'].isin(X_train_S)]\n",
    "training_info_S = training_info_S.set_index(np.arange(len(training_info_S)))\n",
    "training_info_S_mat = training_info_S.as_matrix()\n",
    "content_train = training_info_S_mat[:, 2]\n",
    "\n",
    "vec_train = vectorizer_sender.fit_transform(content_train)\n",
    "bow_train = vec_train.toarray()\n",
    "# test\n",
    "test_info_S = test_info.loc[test_info['mid'].isin(X_dev_S)]\n",
    "test_info_S = test_info_S.set_index(np.arange(len(test_info_S)))\n",
    "test_info_S_mat = test_info_S.as_matrix()\n",
    "content_test = test_info_S_mat[:, 2]\n",
    "\n",
    "vec_test = vectorizer_sender.transform(content_test)\n",
    "bow_test = vec_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n"
     ]
    }
   ],
   "source": [
    "address_books[sender]\n",
    "n_recs = len(address_books[sender])\n",
    "print n_recs\n",
    "Adj = np.concatenate((np.ones((n_recs+1,1)), np.zeros((n_recs+1, n_recs))), axis=1)\n",
    "Adj[0,0] = 0\n",
    "G = nx.from_numpy_matrix(Adj)\n",
    "pos=nx.circular_layout(G)\n",
    "#nx.draw_networkx_labels(G,pos,labels=names,font_size_lab=2, alpha=0.5, font_family='sans-serif')\n",
    "nx.draw_circular(G, node_color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['susan.mara', 'linda.noske', 'wade.cline', 'patrick.keene', 'jose.bestard', 'ray.alvarez', 'carolyn.cooney', 'tom.chapman', 'barbara.hueter', 'brendan.devlin', 'sandra', 'steve.burns', 'dan.staines', 'l..petrochko', 'm..landwehr', 'richard.shapiro', 'susan.scott', 'vinio.floris', 'robert.frank', 'laurie.knight', 'doug.wood', 'pat.shortridge', 'robert.hemstock', 'susan.landwehr', 'alan.comnes', 'l..nicolay', 'ron.mcnamara', 'guillermo.canovas', 'merle.glen', 'dave.mangskau', 'harry.kingerski', 'tom.fitzgibbon', 'teun.biert', 'bryan.gottfredson', 'maria.arefieva', 'lisa.yoho', 'nailia.dindarova', 'nancy.hetrick', 'margaret.huson', 'howard.fromer', 'frank.rishe', 'john.shelk', 'lara.leibman', 'kerry.stroup', 'jan.haizmann', 'paul.hennemeyer', 'larry.decker', 'elizabeth.linnell', 'miyung.buster', 'paul.kaufman', 'alfredo.huertas', 'jean.dressler', 'lysa.tracy', 'daniel.allegretti', 'rubena.buerger', 'alisha.nathoo', 'allen.joe', 'gisele.braz', 'takashi.kimura', 'linda.robertson', 'steve.montovano', 'carin.nersesian', 'sandra.mccubbin', 'nicholas.o', 'janel.guerrero', 'gloria.ogenyi', 'barry.moore', 'mccubbin', 'alberto.levy', 'amber.keenan', 'schuler', 'sue.nord', 'antoine.duvauchelle', 'christopher.long', 'joan.stransky', 'eric.benson', 'sarah.novosel', 'geriann.warner', 'terri.miller', 'dennis.vegas', 'donald.lassere', 'sergio.assad', 'donna.fulton', 'thane.twiggs', '.', 'michael.grimes', 'ramon.alvarez', 'a..hueter', 'robert.neustaedter', 'james.d.steffes', 'lysa', 'j..noske', 'allison.navin', 'chauncey.hood', 'stacey.bolton', 'john.hardy', 'roy.boston', 'w..cantrell', 'mike.roan', 'john.neslage', 'aleck.dadson', 'jeff.dasovich', 'leslie.lawner', 'lysa.akin', 'lora.sullivan', 'kathleen.sullivan', 'marchris.robinson', 'tom.hoatson', 'ban.sharma', 'rebecca.cantrell', 'kirsten.bellas', 'akin', 'lisa.assaf', 'peter.styles', 'carmen.perez', 'tom', 'kerryann.irwin', 'jean.ryall', 'bruno.gaillard', 'bill.moore', 'mika.watanabe', 'mary.hain', 'mark.crowther', 'justyna.ozegalska', 'ginger.dernehl', 'charles.yeung', 'nick.elms', 'bevin.hunter', 'janine.migden', 'makiko.imai', 'paul.dawson', 'stephen.burns', 'lindsay.meade', 'llewelyn.hughes', 'fred.sampaio', 'steven.j.kean', 'luiz.maurer', 'christi.nicolay', 'mike.smith', 'viviana.florio', 'steve.walton', 'mona.petrochko', 'xi.xi', 'jose.reis', 'dave.perrino', 'philip.davies', 'chapman', 'day', 'jennifer.thome', 'joe.allen', 'stella.chan', 'tom.briggs']\n152\n"
     ]
    }
   ],
   "source": [
    "all_recs = get_all_recs_per_sender(training_info_S)\n",
    "all_recs_name = []\n",
    "for recs in all_recs:\n",
    "    all_recs_name.append(recs.split('@')[0])\n",
    "print all_recs_name\n",
    "print len(all_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}